[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "resources",
    "section": "",
    "text": "Rodrigues’ Reproducible Analytical Pipelines in R\nSamantha’s quarto website tutorial\nSamantha’s quarto blog posts tutorial\nMastering Shiny, by Hadley Wickham\nHappy Git and GitHub for the useR, by Jenny Bryan\nR for Data Science, by Hadley Wickham\nHitchhiker’s Guide to Python, by Kenneth Reitz & Tanya Schlusser\nData wrangling essentials: comparisons in JavaScript, Python, SQL, R, and Excel, by Allison Horst & Paul Buffa\nW3Schools, particularly for their HTML & CSS tutorials\nJayde’s parameterized reports with quarto\nMine’s quarto manuscripts"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Portfolio",
    "section": "",
    "text": "R package development\nTaking on package development inculcates in one best practices in programming: using a secluded development environment made possible by {renv} package and Rstudio’s project initialization functionality, documenting code, shared data and publishing user guides to get people started with the software. Package development workflow included {fussen}, {roxygen2}, and {devtools}\nThe packaged is named pbwrangler, it’s goal to document functions used in reading, processing and writing field experimental data in potato breeding.\n\n\nShiny web app\n{shiny} is undoubtedly a go to tool for building a web app that runs in production or just for presenting a proof of concept. I developed a small app as proof that I understand the underlying framework to be able to build an app that can be used in production.\n\n\nReproducible analytical pipelines in R\nThis was a ‘do it yourself too’ as I was reading an online version of Rodrigues’ reproducible piplines text . It reinforced my understanding of package development powered by {fusen}, reproducibility of package versions using {renv}, reproducible pipelines with {targets}, building and sharing docker containers in dockerhub and github, and continuous integration/development (CI/CD) using github actions. A branch with CI/CD running a docker container can be found here.\n\n\nEnd-to-end Machine Learning (MLflow + Docker + Google cloud)\nThis is an account of my learning journey aided by this tutorial to grasp the nitty-gritties of buliding, logging, saving and serving machine learning models. The code available at this repo and a write-up is here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Hello!\nWelcome to my personal (work in progress) site. I am a student enrolled in a Master of Science degree in Statistics and data science, specializing in biostatistics. I use R, SAS, and Python for statistical analysis and visualizations. My interest is statistical computing applied to spatial statistics, infectious diseases modelling and Bayesian data analysis.\n\neducation\n\n\nMS in Biostatistics, 2020 - Ongoing|Hasselt University\n\n\n\nBS in Applied Statistics, 2015|Maseno University\n\n\n\n\n\nexperience\n\n\nBiometrician, 2024-present|International Potato Center (CIP)\n\n\nResearch Assistant, 2022-2023|Karolinska Institutet\n\n\n\nData Manager, 2022-2022|Kenya Medical Research Institute\n\n\n\nData Manager, 2018-2020|KEMRI - Wellcome Trust Research Programme"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)\n\n\n\n\n\n\nQuarto\n\n\nPython\n\n\nMLflow\n\n\n\nWriting R packages using devtools, roxygen2 and usethis packages\n\n\n\n\n\nAug 2, 2025\n\n\nBasil Okola\n\n\n\n\n\n\n\n\n\n\n\n\nR package development guide\n\n\n\n\n\n\nQuarto\n\n\nR\n\n\npackages\n\n\n\nWriting R packages using devtools, roxygen2 and usethis packages\n\n\n\n\n\nDec 16, 2023\n\n\nBasil Okola\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-12-16-R-package dev/index.html",
    "href": "posts/2023-12-16-R-package dev/index.html",
    "title": "R package development guide",
    "section": "",
    "text": "These are quick step-by-step guides I wrote when going through Andy’s fundamentas of package development notes.\n\nInitialize package dev files with devtools::create_package() which creates mandatory file for the package\nEnable git tracking:\n\nconfigure: usethis::use_git_configure()\ncommit: usethis::use_git()\n\nFill in sections of the DESCRIPTION file. {roxygen2} is used to actualize this.\nEdit.Rprofile() to set options you’ll use in the documentation such as author details. This uses usethis::edit_r_profile()\nCreate a separate R file for each function you’ll be including in the package. Use use_r(\"/path-to-file/R/function-name.R\")\nLoad the functions with devtools::load_all()\nCheck the loaded files with check() which runs R CMD checks to catch errors/warnings/notes that need addressing.\nAdd files you don’t wish to include in the package build-in .Rbuildignore file.\nEnable roxygen2 to be used for package documentation: project options -&gt; Build Tools -&gt; check to generate documentation with roxygen or better devtools::document() which generates NAMESPACE automatically\nAutomate external function imports with usethis::use_import_from(): example usethis::use_import_from(“utils”, “install.packages”)\nDocument functions: put the cursor inside the R function definition and ctrl+shift+alt+R to insert the roxygen skeleton. The workflow here is after documenting -&gt; load_all() -&gt; document() -&gt; check()\nData files go to /data dir. It should be of .rda format\nExternal (non .rda format) data go to /inst/extdata/. Document them in the R file e.g. data.R and store it in /R. load_all() then document()\nCall use_package_doc() to add a dummy .R file that will prompt roxygen to generate basic package-level documentation. I noticed doing this erased imports in {package-name}-package.R file. Add recommended imports (see 10) and check()\nInstall your package with devtools::install()\nAttach your package as with other packages by calling library()\nTesting: Using the edit code -&gt; load_all() -&gt; experiment iteration can be unsustainable if you come back to your code months after development. You should write formal tests supported by {testthat} package.\nSet up formal testing of your package with usethis::use_testthat(). Creates a folder /tests. Don’t edit tests/testhat.R\nCall usethis::use_test() e.g., use_test(\"install_load_packages.R\") to edit tests for functions living in a particular R file in R/.\ntest() or ctr + shift + T runs all tests in your test/ directory. The workflow updates to load_all() -&gt; test() -&gt; document() -&gt; check(). Tests should be small and run quickly.\nDependencies, add imports in DESCRIPTION with use_package().\nAdd README with use_readme_rmd()\nRender readme.rmd with build_readme()\nUse continuous integration with use_github_action() then build_readme() again 25 Build a website for your package with use_pkgdown_github_pages() then document().\n\n\n\n\nCitationBibTeX citation:@online{okola2023,\n  author = {Okola, Basil},\n  title = {R Package Development Guide},\n  date = {2023-12-16},\n  url = {https://bokola.github.io/posts/2023-12-16-R-package dev/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nOkola, Basil. 2023. “R Package Development Guide.” December\n16, 2023. https://bokola.github.io/posts/2023-12-16-R-package\ndev/."
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "",
    "text": "BibTeX citation:@online{okola2025,\n  author = {Okola, Basil},\n  title = {End-to-End {Machine} {Learning} {(MLflow} + {Docker} +\n    {Google} {Cloud)}},\n  date = {2025-08-02},\n  url = {https://bokola.github.io/posts/2025-08-02-End-to-end-ML-with-MLflow/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nOkola, Basil. 2025. “End-to-End Machine Learning (MLflow + Docker\n+ Google Cloud).” August 2, 2025. https://bokola.github.io/posts/2025-08-02-End-to-end-ML-with-MLflow/.\nThis is an account of my learning journey aided by this tutorial to grasp the nitty-gritties of buliding, logging, saving and serving machine learning models. First is a description of the development environment used."
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#development-environment",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#development-environment",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Development Environment",
    "text": "Development Environment\nI am running Debian 24.04 LTS, and Pycharm IDE calling Python 3.12 within a .venv virtual environment. Since the model used is a Tensorflow neural network, I had to follow cuda documentation in setting up necessary drives. You also need to start mlflow ui local server by running mlflow ui --port 5000 in the terminal, install dependenices pip install mlflow[extras] hyperopt tensorflow scikit-learn pandas numpy, and set environment variable export MLFLOW_TRACKING_URI=http://localhost:5000."
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-1-data-preparation",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-1-data-preparation",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 1 : Data Preparation",
    "text": "Step 1 : Data Preparation\nThe tutorial uses wine quality classification data.\n#prepare data\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom tensorflow import keras\nimport mlflow\nfrom mlflow.models import infer_signature\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\n#test prediction\nimport requests\nimport json\n\n#environment variables\nload_dotenv(\".env\")\n\nMLFLOW_TRACKING_URI=os.getenv(\"MLFLOW_TRACKING_URI\")\nXLA_FLAGS=os.getenv('XLA_FLAGS')\n\n#load data\ndata = pd.read_csv(\n    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n    sep=\";\",\n)\n\ntrain, test = train_test_split(data, test_size=0.2, random_state=12)\ntrain_x = train.drop([\"quality\"], axis=1).values\ntrain_y = train[[\"quality\"]].values.ravel()\ntest_x = test.drop([\"quality\"], axis=1).values\ntest_y = test[[\"quality\"]].values.ravel()\n\n#further split training data for validation\ntrain_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=12)\n\n#Create model signature for deployment\nsignature = infer_signature(train_x, train_y)"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#define-model-architecture",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#define-model-architecture",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Define Model architecture",
    "text": "Define Model architecture\ndef create_and_train_model(learning_rate, momentum, epochs=10):\n    \"\"\"\n    Create and train a neural network with specified hyperparameters.\n\n    Returns:\n        dict: Training results including model and metrics\n    \"\"\"\n    # Normalize input features for better training stability\n    mean = np.mean(train_x, axis=0)\n    var = np.var(train_x, axis=0)\n\n    # Define model architecture\n    model = keras.Sequential(\n        [\n            keras.Input([train_x.shape[1]]),\n            keras.layers.Normalization(mean=mean, variance=var),\n            keras.layers.Dense(64, activation=\"relu\"),\n            keras.layers.Dropout(0.2),  # Add regularization\n            keras.layers.Dense(32, activation=\"relu\"),\n            keras.layers.Dense(1),\n        ]\n    )\n\n    # Compile with specified hyperparameters\n    model.compile(\n        optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n        loss=\"mean_squared_error\",\n        metrics=[keras.metrics.RootMeanSquaredError()],\n    )\n\n    # Train with early stopping for efficiency\n    early_stopping = keras.callbacks.EarlyStopping(\n        patience=3, restore_best_weights=True\n    )\n\n    # Train the model\n    history = model.fit(\n        train_x,\n        train_y,\n        validation_data=(valid_x, valid_y),\n        epochs=epochs,\n        batch_size=64,\n        callbacks=[early_stopping],\n        verbose=0,  # Reduce output for cleaner logs\n    )\n\n    # Evaluate on validation set\n    val_loss, val_rmse = model.evaluate(valid_x, valid_y, verbose=0)\n\n    return {\n        \"model\": model,\n        \"val_rmse\": val_rmse,\n        \"val_loss\": val_loss,\n        \"history\": history,\n        \"epochs_trained\": len(history.history[\"loss\"]),\n    }\n    ```\n\n## Step 3: Set up parameter optimization\n\ndef objective(params): ““” Objective function for hyperparameter optimization. This function will be called by Hyperopt for each trial. ““” with mlflow.start_run(nested=True): # Log hyperparameters being tested mlflow.log_params( { “learning_rate”: params[“learning_rate”], “momentum”: params[“momentum”], “optimizer”: “SGD”, “architecture”: “64-32-1”, } )\n    # Train model with current hyperparameters\n    result = create_and_train_model(\n        learning_rate=params[\"learning_rate\"],\n        momentum=params[\"momentum\"],\n        epochs=15,\n    )\n\n    # Log training results\n    mlflow.log_metrics(\n        {\n            \"val_rmse\": result[\"val_rmse\"],\n            \"val_loss\": result[\"val_loss\"],\n            \"epochs_trained\": result[\"epochs_trained\"],\n        }\n    )\n\n    # Log the trained model\n    mlflow.tensorflow.log_model(result[\"model\"], name=\"model\", signature=signature)\n\n    # Log training curves as artifacts\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(result[\"history\"].history[\"loss\"], label=\"Training Loss\")\n    plt.plot(result[\"history\"].history[\"val_loss\"], label=\"Validation Loss\")\n    plt.title(\"Model Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(\n        result[\"history\"].history[\"root_mean_squared_error\"], label=\"Training RMSE\"\n    )\n    plt.plot(\n        result[\"history\"].history[\"val_root_mean_squared_error\"],\n        label=\"Validation RMSE\",\n    )\n    plt.title(\"Model RMSE\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"RMSE\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.savefig(\"training_curves.png\")\n    mlflow.log_artifact(\"training_curves.png\")\n    plt.close()\n\n    # Return loss for Hyperopt (it minimizes)\n    return {\"loss\": result[\"val_rmse\"], \"status\": STATUS_OK}"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-5-analyze-results-in-the-mlflow-ui",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-5-analyze-results-in-the-mlflow-ui",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 5: Analyze Results in the MLflow UI",
    "text": "Step 5: Analyze Results in the MLflow UI\n\nNavigate to your experiment → click on “wine-quality-optimization\nAdd key columns: click “columns and add:\n\nMetrics | val_rmse\nParameters | learning_rate\nParameters | momentum\n\nInterprete the visualization: blue lines - better performing runs; red lines - worse performing runs\nAlso take a look at the training curves:\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n# Specify the path to your image file\nimage_path = \"val_rmse.png\"\n\n# Read the image\nimg = mpimg.imread(image_path)\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')  # Hide the axes\nplt.show()\n\n\n\n\n\n\n\n\n\n# Specify the path to your image file\nimage_path = \"training_curves.png\"\n\n# Read the image\nimg = mpimg.imread(image_path)\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')  # Hide the axes\nplt.show()"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-6-register-your-best-model",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-6-register-your-best-model",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 6: Register your best model",
    "text": "Step 6: Register your best model\nTo find the best run: in the table view, click on the run with the lowest val_rmse then navigate to model artifacts and scroll to the “Artifacts” section. then register the model:\n- Go to \"Models\" tab in MLflow UI\n\n- Click on your registered model\n\n- Transition to \"Staging\" stage for testing\n\n- Add tags and descriptions as needed"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-7-deploy-the-best-model",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-7-deploy-the-best-model",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 7: Deploy the best model",
    "text": "Step 7: Deploy the best model\nTest your model with a REST API\n# Serve the model (choose the version number you registered)\nmlflow models serve -m \"models:/wine-quality-predictor/1\" --port 5002\nTest your deployment\n# Test with a sample wine\ncurl -X POST http://localhost:5002/invocations \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"dataframe_split\": {\n      \"columns\": [\n        \"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\",\n        \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\",\n        \"pH\", \"sulphates\", \"alcohol\"\n      ],\n      \"data\": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]]\n    }\n  }'\n\n\nYou could also test with Python\n\nimport requests\nimport json\n\n# Prepare test data\ntest_wine = {\n    \"dataframe_split\": {\n        \"columns\": [\n            \"fixed acidity\",\n            \"volatile acidity\",\n            \"citric acid\",\n            \"residual sugar\",\n            \"chlorides\",\n            \"free sulfur dioxide\",\n            \"total sulfur dioxide\",\n            \"density\",\n            \"pH\",\n            \"sulphates\",\n            \"alcohol\",\n        ],\n        \"data\": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]],\n    }\n}\n\n# Make prediction request\nresponse = requests.post(\n    \"http://localhost:5002/invocations\",\n    headers={\"Content-Type\": \"application/json\"},\n    data=json.dumps(test_wine),\n)\n\nprediction = response.json()\nprint(f\"Predicted wine quality: {prediction['predictions'][0]:.2f}\")"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-8-build-a-production-docker-container",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-8-build-a-production-docker-container",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 8: Build a production Docker container",
    "text": "Step 8: Build a production Docker container\n# Build Docker image\nmlflow models build-docker \\\n  --model-uri \"models:/wine-quality-predictor/1\" \\\n  --name \"wine-quality-api\"\nTest your container:\n# Run the container\ndocker run -p 5003:8080 wine-quality-api\n\n# Test in another terminal\ncurl -X POST http://localhost:5003/invocations \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"dataframe_split\": {\n    \"columns\": [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"],\n    \"data\": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]]\n  }\n}'"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-9-deploy-to-google-cloud",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-9-deploy-to-google-cloud",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 9: Deploy to Google cloud",
    "text": "Step 9: Deploy to Google cloud\n\nAuthentication and project set up\n$ gcloud auth login\nConfigure Docker for gcp $ gcloud auth configure-docker\nset project $ gcloud config set project PROJECT_ID\nIAM roles\n\nArtifacr registry Administrator\nroles/artifactregistry.createOnPushRepoAdmin\nStorage Administrator\n\nExport the credentials export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your-service-account-file.json\"\nTag the docker image\n$ docker tag IMAGE_NAME gcr.io/PROJECT_ID/IMAGE_NAME:TAG\nPush the docker image to Google Cloud Container Registry $ docker push gcr.io/PROJECT_ID/IMAGE_NAME:TAG\n\n\n# Specify the path to your image file\nimage_path = \"gc-artifact-registry.png\"\n\n# Read the image\nimg = mpimg.imread(image_path)\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')  # Hide the axes\nplt.show()\n\n\n\n\n\n\n\n\nsee"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-2-define-model-architecture",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-2-define-model-architecture",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 2: Define Model architecture",
    "text": "Step 2: Define Model architecture\n\ndef create_and_train_model(learning_rate, momentum, epochs=10):\n    \"\"\"\n    Create and train a neural network with specified hyperparameters.\n\n    Returns:\n        dict: Training results including model and metrics\n    \"\"\"\n    #Normalize input features for better training stability\n    mean = np.mean(train_x, axis=0)\n    var = np.var(train_x, axis=0)\n\n    #Define model architecture\n    model = keras.Sequential(\n        [\n            keras.Input([train_x.shape[1]]),\n            keras.layers.Normalization(mean=mean, variance=var),\n            keras.layers.Dense(64, activation=\"relu\"),\n            keras.layers.Dropout(0.2),  # Add regularization\n            keras.layers.Dense(32, activation=\"relu\"),\n            keras.layers.Dense(1),\n        ]\n    )\n\n    #Compile with specified hyperparameters\n    model.compile(\n        optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n        loss=\"mean_squared_error\",\n        metrics=[keras.metrics.RootMeanSquaredError()],\n    )\n\n    #Train with early stopping for efficiency\n    early_stopping = keras.callbacks.EarlyStopping(\n        patience=3, restore_best_weights=True\n    )\n\n    #Train the model\n    history = model.fit(\n        train_x,\n        train_y,\n        validation_data=(valid_x, valid_y),\n        epochs=epochs,\n        batch_size=64,\n        callbacks=[early_stopping],\n        verbose=0,  # Reduce output for cleaner logs\n    )\n\n    #Evaluate on validation set\n    val_loss, val_rmse = model.evaluate(valid_x, valid_y, verbose=0)\n\n    return {\n        \"model\": model,\n        \"val_rmse\": val_rmse,\n        \"val_loss\": val_loss,\n        \"history\": history,\n        \"epochs_trained\": len(history.history[\"loss\"]),\n    }"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-3-set-up-parameter-optimization",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-3-set-up-parameter-optimization",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 3: Set up parameter optimization",
    "text": "Step 3: Set up parameter optimization\n\ndef objective(params):\n    \"\"\"\n    Objective function for hyperparameter optimization.\n    This function will be called by Hyperopt for each trial.\n    \"\"\"\n    with mlflow.start_run(nested=True):\n        #Log hyperparameters being tested\n        mlflow.log_params(\n            {\n                \"learning_rate\": params[\"learning_rate\"],\n                \"momentum\": params[\"momentum\"],\n                \"optimizer\": \"SGD\",\n                \"architecture\": \"64-32-1\",\n            }\n        )\n\n        #Train model with current hyperparameters\n        result = create_and_train_model(\n            learning_rate=params[\"learning_rate\"],\n            momentum=params[\"momentum\"],\n            epochs=15,\n        )\n\n        #Log training results\n        mlflow.log_metrics(\n            {\n                \"val_rmse\": result[\"val_rmse\"],\n                \"val_loss\": result[\"val_loss\"],\n                \"epochs_trained\": result[\"epochs_trained\"],\n            }\n        )\n\n        #Log the trained model\n        mlflow.tensorflow.log_model(result[\"model\"], name=\"model\", signature=signature)\n\n        #Log training curves as artifacts\n        import matplotlib.pyplot as plt\n\n        plt.figure(figsize=(12, 4))\n\n        plt.subplot(1, 2, 1)\n        plt.plot(result[\"history\"].history[\"loss\"], label=\"Training Loss\")\n        plt.plot(result[\"history\"].history[\"val_loss\"], label=\"Validation Loss\")\n        plt.title(\"Model Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n\n        plt.subplot(1, 2, 2)\n        plt.plot(\n            result[\"history\"].history[\"root_mean_squared_error\"], label=\"Training RMSE\"\n        )\n        plt.plot(\n            result[\"history\"].history[\"val_root_mean_squared_error\"],\n            label=\"Validation RMSE\",\n        )\n        plt.title(\"Model RMSE\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"RMSE\")\n        plt.legend()\n\n        plt.tight_layout()\n        plt.savefig(\"training_curves.png\")\n        mlflow.log_artifact(\"training_curves.png\")\n        plt.close()\n\n        #Return loss for Hyperopt (it minimizes)\n        return {\"loss\": result[\"val_rmse\"], \"status\": STATUS_OK}\n\n\n#Define search space for hyperparameters\nsearch_space = {\n    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-5), np.log(1e-1)),\n    \"momentum\": hp.uniform(\"momentum\", 0.0, 0.9),\n}\n\nprint(\"Search space defined:\")\nprint(\"- Learning rate: 1e-5 to 1e-1 (log-uniform)\")\nprint(\"- Momentum: 0.0 to 0.9 (uniform)\")"
  },
  {
    "objectID": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-4-run-the-hyperparameter-optimization",
    "href": "posts/2025-08-02-End-to-end-ML-with-MLflow/index.html#step-4-run-the-hyperparameter-optimization",
    "title": "End-to-end Machine Learning (MLflow + Docker + Google Cloud)",
    "section": "Step 4: Run the hyperparameter optimization",
    "text": "Step 4: Run the hyperparameter optimization\n\n#Create or set experiment\nexperiment_name = \"wine-quality-optimization\"\nmlflow.set_experiment(experiment_name)\n\nprint(f\"Starting hyperparameter optimization experiment: {experiment_name}\")\nprint(\"This will run 15 trials to find optimal hyperparameters...\")\n\nwith mlflow.start_run(run_name=\"hyperparameter-sweep\"):\n    #Log experiment metadata\n    mlflow.log_params(\n        {\n            \"optimization_method\": \"Tree-structured Parzen Estimator (TPE)\",\n            \"max_evaluations\": 15,\n            \"objective_metric\": \"validation_rmse\",\n            \"dataset\": \"wine-quality\",\n            \"model_type\": \"neural_network\",\n        }\n    )\n\n    #Run optimization\n    trials = Trials()\n    best_params = fmin(\n        fn=objective,\n        space=search_space,\n        algo=tpe.suggest,\n        max_evals=15,\n        trials=trials,\n        verbose=True,\n    )\n\n    #Find and log best results\n    best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n    best_rmse = best_trial[\"loss\"]\n\n    #Log optimization results\n    mlflow.log_params(\n        {\n            \"best_learning_rate\": best_params[\"learning_rate\"],\n            \"best_momentum\": best_params[\"momentum\"],\n        }\n    )\n    mlflow.log_metrics(\n        {\n            \"best_val_rmse\": best_rmse,\n            \"total_trials\": len(trials.trials),\n            \"optimization_completed\": 1,\n        }\n    )"
  }
]